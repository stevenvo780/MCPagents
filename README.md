# MCP Autonomous Agents

Servidor MCP (Model Context Protocol) con capacidades aut√≥nomas integradas con OpenAI.

## üöÄ Caracter√≠sticas

- **Servidor MCP Stdio**: Para integraci√≥n con VS Code y Claude Desktop
- **Servidor Web HTTP**: Para APIs REST y integraci√≥n web
- **Integraci√≥n OpenAI**: Soporte completo para todos los modelos de OpenAI (GPT-4o, GPT-5, o1-preview, etc.)
- **An√°lisis de c√≥digo**: Herramientas avanzadas para an√°lisis, optimizaci√≥n y correcci√≥n de c√≥digo
- **Contexto autom√°tico**: Incluye autom√°ticamente el contexto del proyecto (estructura, git, archivos principales)
- **Manejo robusto de errores**: Validaci√≥n completa de entrada y manejo de errores

## üì¶ Instalaci√≥n

```bash
npm install
```

## üîß Configuraci√≥n

1. Crear archivo `.env` (usar `.env.example` como plantilla):
```bash
cp .env.example .env
```

2. Editar `.env` y configurar tu clave API de OpenAI:
```bash
OPENAI_API_KEY=tu_clave_de_openai_aqu√≠
OPENAI_MODEL=gpt-4o-mini
```

## üéØ Uso

### Servidor MCP (Para VS Code/Claude Desktop)

1. Compilar TypeScript:
```bash
npm run build
```

2. Probar servidor MCP:
```bash
echo '{"jsonrpc":"2.0","id":1,"method":"tools/list","params":{}}' | node dist/mcp/stdio-server.js
```

### Servidor Web HTTP

```bash
npm start
# o para desarrollo con auto-reload:
npm run dev:web
```

### Endpoints Web

- `GET /health` - Health check
- `GET /` - Informaci√≥n del servidor y endpoints disponibles
- `GET /api/models` - Lista de modelos soportados
- `POST /api/ask` - Hacer preguntas al asistente IA
- `POST /api/analyze` - Analizar c√≥digo
- `POST /jsonrpc` - Endpoint JSON-RPC para compatibilidad MCP

## üõ†Ô∏è Herramientas MCP Disponibles

### 1. `autonomous_ask`
Hace preguntas al asistente IA con contexto autom√°tico del proyecto.

**Par√°metros:**
- `question` (requerido): La pregunta a hacer
- `system` (opcional): Prompt del sistema para guiar la respuesta
- `temperature` (opcional): Temperatura para creatividad (0-2, default: 0.7)
- `maxTokens` (opcional): M√°ximo tokens en respuesta (default: 2000)
- `context` (opcional): Contexto adicional
- `includeProjectContext` (opcional): Incluir contexto autom√°tico del proyecto (default: true)

### 2. `analyze_code`
Analiza c√≥digo con el asistente IA y contexto autom√°tico del proyecto.

**Par√°metros:**
- `code` (requerido): El c√≥digo a analizar
- `language` (opcional): Lenguaje de programaci√≥n (default: "typescript")
- `task` (opcional): Tipo de an√°lisis ("analyze", "fix", "optimize", "explain", default: "analyze")
- `includeProjectContext` (opcional): Incluir contexto autom√°tico del proyecto (default: true)

### 3. `get_project_context`
Obtiene contexto completo del proyecto incluyendo estructura, estado de git y archivos principales.

### 4. `health_check`
Verifica el estado de salud del servidor.

## üíª Integraci√≥n con VS Code

1. Instalar la extensi√≥n MCP para VS Code
2. Configurar el servidor en la configuraci√≥n de VS Code:

```json
{
  "mcp.servers": {
    "autonomous-agent": {
      "command": "node",
      "args": ["dist/mcp/stdio-server.js"],
      "cwd": "/ruta/completa/a/MCPagents",
      "env": {
        "OPENAI_API_KEY": "tu-openai-api-key-aqu√≠"
      }
    }
  }
}
```

## üß™ Pruebas

### Probar el servidor web:
```bash
# Health check
curl http://localhost:8080/health

# Listar modelos
curl http://localhost:8080/api/models

# Hacer pregunta (falla sin API key configurada)
curl -X POST http://localhost:8080/api/ask \\
  -H "Content-Type: application/json" \\
  -d '{"question":"Hello, how are you?"}'
```

### Probar el servidor MCP:
```bash
# Listar herramientas
echo '{"jsonrpc":"2.0","id":1,"method":"tools/list","params":{}}' | node dist/mcp/stdio-server.js

# Obtener contexto del proyecto
echo '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"get_project_context","arguments":{}}}' | node dist/mcp/stdio-server.js

# Verificar salud
echo '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"health_check","arguments":{}}}' | node dist/mcp/stdio-server.js
```

## üéõÔ∏è Modelos Soportados

El servidor detecta autom√°ticamente el modelo configurado y ajusta los par√°metros:

- **GPT-5**: Modelo de razonamiento flagship (requiere `max_completion_tokens`, m√≠nimo 2000 tokens)
- **o1-preview**: Razonamiento avanzado m√°ximo (hasta 32,768 tokens)
- **o1-mini**: Razonamiento eficiente (hasta 65,536 tokens)
- **gpt-4o**: Multimodal flagship (hasta 16,384 tokens)
- **gpt-4o-mini**: Econ√≥mico (hasta 16,384 tokens)
- **gpt-4-turbo**: GPT-4 optimizado (hasta 4,096 tokens)
- **gpt-4**: Modelo cl√°sico potente (hasta 8,192 tokens)
- **gpt-3.5-turbo**: R√°pido y econ√≥mico (hasta 4,096 tokens)

## üìã Scripts Disponibles

- `npm run build` - Compilar TypeScript
- `npm start` - Iniciar servidor web
- `npm run dev:web` - Desarrollo servidor web (con watch)
- `npm run dev:stdio` - Desarrollo servidor MCP con ts-node
- `npm run start:stdio` - Iniciar servidor MCP compilado

## üîß Desarrollo

Para desarrollo, usar:
```bash
# Terminal 1: Compilaci√≥n autom√°tica
npm run build -- --watch

# Terminal 2: Servidor web con auto-reload
npm run dev:web

# Terminal 3: Probar servidor MCP
npm run dev:stdio
```

## üö® Soluci√≥n de Problemas

### Error: "OPENAI_API_KEY no est√° configurada"
- Verificar que el archivo `.env` existe y contiene `OPENAI_API_KEY=tu_clave_aqu√≠`
- No usar `your-openai-api-key-here` como valor real

### Error: "Unknown file extension .ts"
- Ejecutar `npm run build` primero para compilar TypeScript
- Usar `node dist/mcp/stdio-server.js` en lugar de archivos `.ts`

### Servidor no responde
- Verificar que el puerto 8080 no est√© ocupado
- Revisar logs para errores espec√≠ficos
- Probar health check: `curl http://localhost:8080/health`

## üìù Logs y Debugging

El servidor incluye logging detallado:
- Informaci√≥n del modelo detectado
- Par√°metros de configuraci√≥n autom√°tica
- Errores de API con detalles completos
- Contexto del proyecto en cada solicitud